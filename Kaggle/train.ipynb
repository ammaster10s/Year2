{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy import fftpack as fft\n",
    "import cv2\n",
    "import pandas as pd\n",
    "\n",
    "classes = [\"fall\", \"jump\", \"not_fall\", \"run\", \"run_sit\", \"sit_run\", \"walk\"]\n",
    "\n",
    "overlap = 128\n",
    "n_rd_history = 256\n",
    "overlap_count = 0\n",
    "min_iq = 0\n",
    "max_iq = 0.05\n",
    "min_rf = 0\n",
    "max_rf = 45\n",
    "\n",
    "\n",
    "class CSVDopplerDatagen(Dataset):\n",
    "    def __init__(self,\n",
    "                 csv='/mnt/c/Users/Admin/Downloads/work/uwb/uwb-pose-prediction/annotations.csv',\n",
    "                 src='/mnt/c/Users/Admin/Downloads/work/uwb/uwb-pose-prediction/train/train'):\n",
    "        self.csv = pd.read_csv(csv).fillna(-1)\n",
    "        self.src = src\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.csv)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.csv.iloc[idx]\n",
    "        iq = np.load(os.path.join(\n",
    "            self.src,\n",
    "            row['id'] + '.npy'\n",
    "        ))\n",
    "        if iq.shape[0] > 2560:\n",
    "            iq = iq[-2560:]\n",
    "        range_frequency = self.range_frequency([iq])[0]\n",
    "        image = np.stack((\n",
    "            iq / max_iq,\n",
    "            range_frequency / max_rf,\n",
    "            np.zeros_like(iq),\n",
    "        ))\n",
    "        return image, row['class']\n",
    "\n",
    "    @staticmethod\n",
    "    def range_frequency(datas):\n",
    "        Range_frequency_frame = []\n",
    "        for data in datas:\n",
    "            jitter = 1e-10\n",
    "            noise_threshold = -45\n",
    "            dB = True\n",
    "            rd_history = np.hanning(data.shape[0])[:, None] * np.array(data)\n",
    "            # Range-Doppler\n",
    "            rd = fft.fft(rd_history, axis=0)\n",
    "            rd = fft.fftshift(rd, axes=0)\n",
    "            rd = abs(rd)\n",
    "            if dB:\n",
    "                rd = 20 * np.log10(rd + jitter)\n",
    "                rd[rd < noise_threshold] = noise_threshold\n",
    "            Range_frequency_frame.append(rd)\n",
    "        return np.stack(Range_frequency_frame)\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    dset = CSVDopplerDatagen()\n",
    "    min_rf = float('inf')\n",
    "    min_iq = float('inf')\n",
    "    max_rf = -float('inf')\n",
    "    max_iq = -float('inf')\n",
    "    lengths = {2560: 0, 7680: 0}\n",
    "    for i in range(len(dset)):\n",
    "        data, _ = dset[i]\n",
    "        # min_iq = min(min_iq, np.abs(data[0]).min())\n",
    "        # max_iq = max(max_iq, np.abs(data[0]).max())\n",
    "        # min_rf = min(min_rf, np.abs(data[1]).min())\n",
    "        # max_rf = max(max_rf, np.abs(data[1]).max())\n",
    "        lengths[data.shape[1]] += 1\n",
    "    x = dset[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from timm.models import convnext\n",
    "\n",
    "class ViTCls(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = convnext.convnext_base(pretrained=True)\n",
    "        self.cls = nn.Linear(self.encoder.num_features, 7)\n",
    "\n",
    "    def forward(self, images):\n",
    "        x = self.encoder.forward_features(images)\n",
    "        x = self.encoder.forward_head(x, pre_logits=True)\n",
    "        y = self.cls(x)\n",
    "        return y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Epoch: 1\n",
      "81/81 [==============================] - 38s 468ms/step - loss2: 2.0390 - acc: 0.1704\n",
      "Epoch: 2\n",
      "81/81 [==============================] - 39s 474ms/step - loss2: 1.9260 - acc: 0.1698\n",
      "Epoch: 3\n",
      "81/81 [==============================] - 39s 481ms/step - loss2: 1.6742 - acc: 0.3713\n",
      "Epoch: 4\n",
      "81/81 [==============================] - 40s 489ms/step - loss2: 1.3947 - acc: 0.5161\n",
      "Epoch: 5\n",
      "81/81 [==============================] - 39s 483ms/step - loss2: 1.1753 - acc: 0.5642\n",
      "Epoch: 6\n",
      "81/81 [==============================] - 40s 486ms/step - loss2: 1.0139 - acc: 0.6182\n",
      "Epoch: 7\n",
      "81/81 [==============================] - 40s 486ms/step - loss2: 0.8510 - acc: 0.7352\n",
      "Epoch: 8\n",
      "81/81 [==============================] - 40s 488ms/step - loss2: 0.6905 - acc: 0.8007\n",
      "Epoch: 9\n",
      "81/81 [==============================] - 40s 485ms/step - loss2: 0.5120 - acc: 0.8408\n",
      "Epoch: 10\n",
      "81/81 [==============================] - 40s 486ms/step - loss2: 0.4466 - acc: 0.8655\n",
      "Epoch: 11\n",
      "81/81 [==============================] - 40s 484ms/step - loss2: 0.2559 - acc: 0.9506\n",
      "Epoch: 12\n",
      "81/81 [==============================] - 40s 484ms/step - loss2: 0.2025 - acc: 0.9643\n",
      "Epoch: 13\n",
      "81/81 [==============================] - 40s 489ms/step - loss2: 0.1754 - acc: 0.9738\n",
      "Epoch: 14\n",
      "81/81 [==============================] - 40s 487ms/step - loss2: 0.1573 - acc: 0.9846\n",
      "Epoch: 15\n",
      "81/81 [==============================] - 40s 486ms/step - loss2: 0.1458 - acc: 0.9861\n"
     ]
    }
   ],
   "source": [
    "from models import ViTCls\n",
    "from datagen import CSVDopplerDatagen\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "import torch\n",
    "from timm.scheduler.cosine_lr import CosineLRScheduler\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import KFold\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    n_epochs = 15\n",
    "    batch_size = 8\n",
    "    n_folds = 5\n",
    "    device = 'cuda'\n",
    "    model = ViTCls().to(device)\n",
    "    print(0)\n",
    "    data = {'fold': [], 'epoch': [], 'acc': [], 'mse': [], 'cce': []}\n",
    "\n",
    "    train_dataset = CSVDopplerDatagen()\n",
    "    val_dataset = CSVDopplerDatagen(csv='/mnt/c/Users/Admin/Downloads/work/uwb/uwb-pose-prediction/sample_submission.csv',\n",
    "                                    src='/mnt/c/Users/Admin/Downloads/work/uwb/uwb-pose-prediction/test/test')\n",
    "    val_dataset.csv = val_dataset.csv.fillna(-1)\n",
    "    train_loader = DataLoader(train_dataset,\n",
    "                              batch_size=batch_size,\n",
    "                              shuffle=True,\n",
    "                              num_workers=4\n",
    "                              )\n",
    "    val_loader = DataLoader(val_dataset,\n",
    "                            batch_size=1,\n",
    "                            shuffle=False,\n",
    "                            num_workers=4\n",
    "                            )\n",
    "\n",
    "    criterion2 = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n",
    "    schedule = CosineLRScheduler(optimizer,\n",
    "                                 t_initial=n_epochs,\n",
    "                                 cycle_mul=1,\n",
    "                                 lr_min=1e-6,\n",
    "                                 cycle_decay=0.1,\n",
    "                                 warmup_lr_init=1e-7,\n",
    "                                 warmup_t=10,\n",
    "                                 cycle_limit=1,\n",
    "                                 t_in_epochs=True,\n",
    "                                 noise_range_t=None,\n",
    "                                 )\n",
    "    max_acc = 0\n",
    "    for epoch in range(n_epochs):\n",
    "        print('Epoch:', epoch + 1)\n",
    "        progbar = tf.keras.utils.Progbar(len(train_loader))\n",
    "        model.train()\n",
    "        for idx, (x, cls) in enumerate(train_loader):\n",
    "            # data_ft = data_ft.to(device)\n",
    "            # data_dt = data_dt.to(device)\n",
    "            x = x.to(device).float()\n",
    "            cls = cls.to(device)\n",
    "            # output = model(data_ft, data_dt)\n",
    "            logit = model(\n",
    "                x  # [:, 0]\n",
    "            )\n",
    "            loss = criterion2(logit, cls)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            _, predicted = logit.max(1)\n",
    "            acc = predicted.eq(cls).sum().item() / cls.size(0)\n",
    "            optimizer.step()\n",
    "            printlog = [\n",
    "                # ('loss1', loss1.cpu().detach().numpy()),\n",
    "                ('loss2', loss.cpu().detach().numpy()),\n",
    "                ('acc', acc)\n",
    "            ]\n",
    "            progbar.update(idx + 1, printlog)\n",
    "        schedule.step(epoch + 1)\n",
    "        model.eval()\n",
    "        progbar = tf.keras.utils.Progbar(len(val_loader))\n",
    "        predict = []\n",
    "        with torch.no_grad():\n",
    "            for idx, (x, cls) in enumerate(val_loader):\n",
    "                if cls[0] > -1:\n",
    "                    predict.extend(cls.cpu().detach().numpy().tolist())\n",
    "                    continue\n",
    "                x = x.to(device).float()\n",
    "                cls = cls.to(device)\n",
    "                logit = model(\n",
    "                    x  # [:, 0]\n",
    "                )\n",
    "                _, predicted = logit.max(1)\n",
    "                predict.extend(predicted.cpu().detach().numpy().tolist())\n",
    "        df = val_dataset.csv.copy()\n",
    "        df['class'] = predict\n",
    "        df.to_csv(f'logs/json_files/{epoch:02d}.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "caption",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "d0557c582b3fc8a6d1af0a808c55663a1814553745bd196f1788104f2c26fa91"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
